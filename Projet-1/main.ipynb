{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implémentation de la Rétropropagation du Gradient dans un Réseau de Neurones**\n",
    "\n",
    "### **Elyes KHALFALLAH - 5230635**\n",
    "\n",
    "04/11/2024\n",
    "\n",
    "---\n",
    "\n",
    "Ce projet consiste à implémenter un réseau de neurones simple en Python, en se concentrant sur l'algorithme de rétropropagation du gradient. L'objectif est de comprendre en profondeur les mécanismes de la rétropropagation et de voir son efficacité dans un contexte de classification binaire.\n",
    "\n",
    "Nous suivrons une architecture de type Perceptron Multicouche (MLP) avec plusieurs couches et neurones, en utilisant différents types de fonctions d'activation (Sigmoïde, ReLU, et Tanh) pour mieux comprendre leur influence sur la convergence du modèle.\n",
    "\n",
    "## **Plan du projet**\n",
    "\n",
    "1. **Initialisation des paramètres** : Création des poids et biais pour chaque couche en utilisant l'initialisation Xavier, afin de prévenir les problèmes de saturation des gradients.\n",
    "2. **Propagation avant** : Calcul des activations pour chaque couche, en appliquant la fonction d'activation choisie.\n",
    "3. **Fonction de coût** : Calcul du coût à chaque itération, ici basée sur l'erreur des moindres carrés (comme spécifié).\n",
    "4. **Rétropropagation** : Calcul des gradients des poids et des biais via la rétropropagation, en ajustant les paramètres pour minimiser le coût.\n",
    "5. **Mise à jour des paramètres** : Utilisation du taux d'apprentissage pour ajuster les poids et biais en fonction des gradients calculés.\n",
    "6. **Critère d'arrêt** : L'entraînement s'arrête lorsque le coût est inférieur à un seuil prédéfini, ou après un nombre maximal d'itérations.\n",
    "7. **Tests sur des fonctions logiques (AND, OR, XOR)** : Validation du bon fonctionnement de l'algorithme en utilisant des jeux de données simples.\n",
    "8. **Visualisation des frontières de décision et de l'évolution du coût** : Illustration des résultats pour mieux comprendre la performance et la convergence du réseau.\n",
    "\n",
    "Cette implémentation suit les instructions du cours pour assurer une compréhension complète de chaque étape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Initialisation des Paramètres**\n",
    "\n",
    "L'initialisation des paramètres, c'est-à-dire des poids et des biais, est essentielle pour le bon fonctionnement de l'algorithme de rétropropagation. Dans cette implémentation, nous utilisons une méthode appelée **initialisation Xavier**. Elle ajuste les poids de chaque couche de manière à faciliter la propagation des informations à travers le réseau, ce qui aide à éviter les problèmes de gradients trop faibles ou trop grands.\n",
    "\n",
    "ChatGPT m'a proposé d'utiliser l'initialisation Xavier quand j'ai remarqué que mes tests n'étaient pas satisfaisants. L'implémentation de cette methode d'initialisation à instantanément amélioré mes résultats, faisant que les tests AND et OR qu'on verra plus tard se sont fait en moins d'iterations, et aussi fait que la fonction XOR ait enfin convergé.\n",
    "\n",
    "### Détails de l'initialisation :\n",
    "\n",
    "1. **Poids `W`** : Pour chaque couche `l`, les poids `W[l]` sont initialisés à partir d'une distribution normale, ajustée selon la taille de la couche précédente.\n",
    "2. **Biais `b`** : Initialisés à zéro pour chaque couche.\n",
    "\n",
    "L'initialisation Xavier est particulièrement utile pour les réseaux de neurones multicouches et aide à une meilleure convergence pendant l'apprentissage.\n",
    "\n",
    "La fonction `initialize_parameters` prend en entrée la liste `layer_dims`, qui indique le nombre de neurones dans chaque couche du réseau, et retourne un dictionnaire avec les poids et biais initialisés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Propagation Avant**\n",
    "\n",
    "La propagation avant est l'étape où l'on fait passer les données d'entrée `X` à travers les différentes couches du réseau pour obtenir une sortie finale. A chaque couche, les poids et les biais sont appliqués, puis une fonction d'activation (sigmoïde, ReLU, tanh, autre) est utilisée pour introduire de la non-linéarité, ce qui permet au réseau de modéliser des relations complexes.\n",
    "\n",
    "### Détails de la propagation :\n",
    "\n",
    "1. **Calcul de `z`** : Pour chaque couche `l`, on calcule `z = W[l] * A_prev + b[l]`, où `A_prev` est l'activation de la couche précédente.\n",
    "2. **Application de la fonction d'activation** : La fonction d'activation choisie (`sigmoïde`, `ReLU` ou `tanh`) est appliquée à `z` pour obtenir l'activation `A` de la couche actuelle.\n",
    "\n",
    "Ce processus se répète pour chaque couche jusqu'à atteindre la dernière couche, qui donne la prédiction finale du réseau. La fonction `forward_propagation` renvoie les activations de chaque couche, ainsi que les valeurs intermédiaires `z`.\n",
    "\n",
    "Cette approche est énoncée dans les slides 46/86 (29/44) du document _ANN_VELCIN.pdf_ (les slides du cours).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Calcul de la Fonction de Cout**\n",
    "\n",
    "La fonction de coût mesure la différence entre la sortie prédite par le réseau et la sortie réelle attendue. Dans cette implémentation, nous utilisons l'erreur quadratique moyenne (ou erreur des moindres carrés), qui est adaptée aux tâches de régression et de classification binaire.\n",
    "\n",
    "### Détails du calcul :\n",
    "\n",
    "1. **Formule de la fonction de coût** : Pour `m` exemples dans le jeu de données, la fonction de coût est calculée comme suit :\n",
    "\n",
    "   $$ \\text{Coût} = \\frac{1}{2m} \\sum*{i=1}^{m} (Y*{\\text{prédit}}^{(i)} - Y\\_{\\text{réel}}^{(i)})^2 $$\n",
    "\n",
    "2. **Objectif** : Minimiser cette fonction de coût en ajustant les poids et biais du réseau à travers l'algorithme de rétropropagation.\n",
    "\n",
    "Cette étape fournit une mesure quantitative de l'erreur, qui sera utilisée pour évaluer la performance du réseau au fur et à mesure de l'apprentissage. Pour plus de détails, voir les slides 65/86 (36/44) du document _ANN_VELCIN.pdf_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Rétropropagation**\n",
    "\n",
    "La rétropropagation est un algorithme permettant de calculer les gradients des paramètres du réseau (poids et biais) en fonction de la fonction de coût. Ces gradients sont ensuite utilisés pour ajuster les paramètres et réduire l'erreur du réseau au fur et a mesure des itérations.\n",
    "\n",
    "### Principe de la rétropropagation :\n",
    "\n",
    "1. **Propagation arrière** : L'algorithme commence par calculer l'erreur pour la dernière couche.\n",
    "2. **Calcul des gradients** : Ensuite, l'erreur est rétropropagée dans les couches du réseau, en calculant les dérivées de la fonction de coût par rapport aux poids et biais de chaque couche. Cette étape utilise la **règle de la chaîne** pour déterminer l'influence de chaque paramètre sur l'erreur finale.\n",
    "3. **Fonction d'activation** : La dérivée de la fonction d'activation choisie (sigmoïde, ReLU, ou tanh) est également utilisée pour ajuster la contribution de chaque couche en fonction de son activation.\n",
    "\n",
    "### Formule de la rétropropagation pour la dernière couche :\n",
    "\n",
    "Pour la dernière couche $ L $, le gradient de la fonction de coût par rapport à la sortie est donné par :\n",
    "   $$ \\delta_L = (A^{(L)} - Y) \\cdot f'(Z^{(L)}) $$\n",
    "où :\n",
    "\n",
    "- $ A^{(L)} $ est l'activation de la dernière couche.\n",
    "- $ Y $ est la sortie réelle.\n",
    "- $ f'(Z^{(L)}) $ est la dérivée de la fonction d'activation appliquée à $ Z^{(L)} $.\n",
    "\n",
    "Pour les couches cachées, la rétropropagation suit des étapes similaires, mais en tenant compte des gradients calculés dans les couches suivantes. La rétropropagation est fondamentale pour l'apprentissage du réseau car elle ajuste les paramètres pour que le réseau s'approche de la solution optimale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Mise à jour des paramètres**\n",
    "\n",
    "Après avoir calculé les gradients pour chaque couche à l'aide de la rétropropagation, on utilise ces gradients pour ajuster les poids et les biais de chaque couche. La mise à jour des paramètres suit la règle de gradient descendante, qui consiste à faire un petit pas dans la direction qui minimise la fonction de coût. Cela s’écrit pour chaque couche $l$ :\n",
    "\n",
    "1. **Mise à jour des poids** :\n",
    "   $$ W^{(l)} = W^{(l)} - \\alpha \\times dW^{(l)} $$\n",
    "\n",
    "2. **Mise à jour des biais** :\n",
    "   $$ b^{(l)} = b^{(l)} - \\alpha \\times db^{(l)} $$\n",
    "\n",
    "Ici, **dW** et **db** représentent les gradients des poids et des biais pour la couche $l$, et $\\alpha$ est le taux d'apprentissage (ou learning_rate), un paramètre fixe qui détermine la taille du pas de mise à jour.\n",
    "\n",
    "Ces mises à jour des paramètres sont appliquées à chaque itération de l’entraînement, ce qui permet au réseau d’optimiser les poids et biais pour mieux prédire les sorties attendues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Critère d'arrêt de l'entraînement**\n",
    "\n",
    "Le critère d'arrêt dans l'entraînement d'un réseau de neurones est important pour éviter les calculs inutiles ou la surentraînement. Dans notre modèle, nous définissons deux possiblités pour mettre fin à l'entraînement :\n",
    "\n",
    "1. **Seuil de coût** : Lorsque la valeur de la fonction de coût descend en dessous d'un seuil défini, l'entraînement s'arrête. Ce seuil est fixé pour atteindre une précision acceptable.\n",
    "\n",
    "2. **Nombre maximum d'itérations** : Un nombre maximum d'itérations est spécifié pour s'assurer que l'entraînement ne continue pas indéfiniment.\n",
    "\n",
    "Ces critères permettent de contrôler la durée de l'entraînement et de s'assurer que le modèle a atteint une performance raisonnable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Fonctions logiques et tests**\n",
    "\n",
    "Pour évaluer les performances de notre modèle de rétropropagation, nous utilisons des fonctions logiques simples : **AND**, **OR**, et **XOR**. Ces fonctions permettent de tester si le réseau de neurones est capable d'apprendre des relations logiques de base, linéairement solvables ou non.\n",
    "\n",
    "La fonction XOR est particulièrement intéressante car elle est non-linéaire, ce qui la rend difficile à modéliser avec un perceptron simple. Pour cette raison, le réseau a besoin de plusieurs couches pour capturer cette relation complexe.\n",
    "\n",
    "Pour chaque fonction logique, nous entraînons le réseau et traçons l'évolution du coût ainsi que les frontières de décision. Cela permet de visualiser la manière dont le réseau a appris la séparation entre les classes 0 et 1 pour chaque fonction logique.\n",
    "\n",
    "Vous trouverez les tests dans les cellules ci-dessous.\n",
    "\n",
    "Vous pouvez consulter les résultats et les graphiques dans les dossiers générés sous `results/` APRES AVOIR LANCE LE CODE AU MOINS UNE FOIS pour chaque fonction d'activation, chaque modele de couches, et chaque fonction logique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "Dans ce projet, nous avons construit un modèle de rétropropagation du gradient complet et flexible, capable d'apprendre des relations logiques simples avec différentes configurations de couches et fonctions d'activation. Le cœur de ce travail a porté sur la compréhension et l'implémentation de la rétropropagation, qui permet d'ajuster les paramètres du réseau pour minimiser l'erreur et s'adapter aux données d'entraînement.\n",
    "\n",
    "Les fonctions logiques AND et OR, qui sont plus simples, ont été correctement apprises dans la majorité des cas. Cependant, même avec ces fonctions relativement faciles, certaines configurations, notamment avec les fonction d'activation ReLU et Tanh, ont souvent échoué (mais cela s’explique par le fait qu'elles est moins adaptée pour ce type de problème logique binaire).\n",
    "\n",
    "Quant à la fonction logique XOR, plus complexe à séparer linéairement, la réussite de son apprentissage a été variable, dépendant fortement des paramètres initiaux. Certaines exécutions ont donné des résultats satisfaisants tandis que d’autres ont échoué, ce qui reflète la nature stochastique de l'initialisation des paramètres. Malheureusement, je n'ai pas pu trouver de seed de départ qui garantisse systématiquement la réussite de l'apprentissage pour XOR.\n",
    "\n",
    "Les résultats obtenus, visibles dans les graphes de coût et les frontières de décision, illustrent l’impact de la rétropropagation, qui ajuste les paramètres du réseau en réponse aux erreurs mesurées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# CODE A LANCER POUR OBTENIR TOUS LES RESULTATS\n",
    "\n",
    "Rappels :\n",
    "\n",
    "- Sigmoide est la meilleure a regarder\n",
    "- Les données sont générées aléatoirement dans la fonction `initialize_parameters` dans `fonctions.py`. Si on veut ajouter une graine, décommenter la ligne `60`\n",
    "\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonctions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée le répertoire \"results\" s'il n'existe pas déjà\n",
    "os.makedirs(\"results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données pour les fonctions logiques\n",
    "logic_functions = {\n",
    "    \"AND\": {\n",
    "        \"INPUT\": np.array([[0, 0, 1, 1], [0, 1, 0, 1]]),\n",
    "        \"OUTPUT\": np.array([[0, 0, 0, 1]]),\n",
    "    },\n",
    "    \"OR\": {\n",
    "        \"INPUT\": np.array([[0, 0, 1, 1], [0, 1, 0, 1]]),\n",
    "        \"OUTPUT\": np.array([[0, 1, 1, 1]]),\n",
    "    },\n",
    "    \"XOR\": {\n",
    "        \"INPUT\": np.array([[0, 0, 1, 1], [0, 1, 0, 1]]),\n",
    "        \"OUTPUT\": np.array([[0, 1, 1, 0]]),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#      \"sigmoid\", \"relu\", \"tanh\" SONT LES TROIS FONCTIONS DISPONIBLES, SI VOUS VOULEZ EN ENLEVER, EFFACEZ LES DE LA LISTE SUIVANTE\n",
    "#\n",
    "#      [\"sigmoid\", \"relu\", \"tanh\"]\n",
    "\n",
    "activation_functions = [\"sigmoid\", \"relu\", \"tanh\"]\n",
    "\n",
    "# Parametrages des couches de neurones à tester\n",
    "layer_dims_list = [\n",
    "    [2, 1],  # Simple, sans couche cachée\n",
    "    [2, 4, 1],  # Une couche cachée relativement petite\n",
    "    [2, 100, 1],  # Une couche cachée relativement grande\n",
    "    [2, 8, 8, 1],  # Plusieures couches cachées moyennes\n",
    "    [2, 16, 16, 1],  # Plusieures couches cachées moyennes\n",
    "    [2, 3, 5, 3, 1],  # Beaucoup de petites couches cachées\n",
    "]\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 0.005\n",
    "max_iterations = 250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#     LE LANCEMENT DE CETTE CELLULE M'A PRIT 4min 20s SUR MON PC PERSONNEL\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "for activation_fn in activation_functions:\n",
    "    # Crée un répertoire pour chaque fonction d'activation (sigmoid, relu, tanh) dans \"results\"\n",
    "    activation_dir = os.path.join(\"results\", activation_fn)\n",
    "    os.makedirs(activation_dir, exist_ok=True)\n",
    "\n",
    "    for layer_dims in layer_dims_list:\n",
    "        # Crée un sous-répertoire pour chaque architecture de réseau (par exemple, [2, 4, 1]) dans le répertoire de la fonction d'activation\n",
    "        architecture_dir = os.path.join(activation_dir, str(layer_dims))\n",
    "        os.makedirs(architecture_dir, exist_ok=True)\n",
    "\n",
    "        for func_name, data in logic_functions.items():\n",
    "            # Pour chaque fonction logique (AND, OR, XOR), extrait les données d'entrée (X_test) et de sortie (Y_test)\n",
    "            X_test, Y_test = data[\"INPUT\"], data[\"OUTPUT\"]\n",
    "\n",
    "            # Entraîne le modèle avec les données et paramètres actuels\n",
    "            parameters, costs = train_model(\n",
    "                X_test,\n",
    "                Y_test,\n",
    "                layer_dims,\n",
    "                learning_rate,\n",
    "                threshold,\n",
    "                max_iterations,\n",
    "                activation_fn,\n",
    "            )\n",
    "\n",
    "            # Définit le nom de fichier pour l'image combinant l'évolution du coût et la frontière de décision\n",
    "            combined_plot_filename = os.path.join(\n",
    "                architecture_dir, f\"{func_name}_combined.png\"\n",
    "            )\n",
    "\n",
    "            # Génère et sauvegarde un graphique combiné de l'évolution du coût et des frontières de décision pour la fonction logique actuelle\n",
    "            plot_cost_and_decision_boundary(\n",
    "                X_test,\n",
    "                Y_test,\n",
    "                parameters,\n",
    "                costs,\n",
    "                title=f\"{func_name} ({activation_fn}, {layer_dims})\",\n",
    "                filename=combined_plot_filename,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
