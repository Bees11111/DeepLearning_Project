{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning - Rendu n°2 : Cas d'études**\n",
    "\n",
    "Elyes KHALFALLAH - 5230635\n",
    "\n",
    "13/12/2024\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 :** Jeu de données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 :** Quelques statistiques descriptives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des fichiers CSV\n",
    "train_df = pd.read_csv(\"train.csv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"test.csv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les quelques premieres lignes\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les types des données de chaque colonnes\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `float64(9)`, `int64(4)`, nous avons 13 données de type quantitatives\n",
    "- `object(7)`, nous avons 7 données de type descriptives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par approfondir notre analyse : examinons quelques statistiques descriptives sur les variables quantitatives. Nous observerons aussi la distribution des genres et sous-genres afin de mieux comprendre la répartition des pistes dans notre ensemble de données. Ce premier aperçu nous aidera à saisir les principales tendances et à identifier d’éventuels déséquilibres dans les catégories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir des statistiques descriptives des colonnes numériques\n",
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des genres musicaux des morceaux regardés\n",
    "genre_counts = train_df[\"playlist_genre\"].value_counts()\n",
    "print(genre_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des sous-genres musicaux des morceaux regardés\n",
    "subgenre_counts = train_df[\"playlist_subgenre\"].value_counts()\n",
    "print(subgenre_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogrammes des distributions des variables numériques\n",
    "\n",
    "num_cols = [\n",
    "    \"track_popularity\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"key\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\",\n",
    "    \"duration_ms\",\n",
    "]\n",
    "\n",
    "train_df[num_cols].hist(figsize=(16, 16))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de poursuivre, nous allons explorer visuellement plusieurs aspects clés de notre jeu de données. Nous commencerons par un histogramme illustrant la distribution des genres, puis nous examinerons la matrice de corrélation afin d’identifier les relations entre les variables quantitatives. Nous calculerons également la popularité moyenne des pistes par genre et, enfin, nous visualiserons la relation entre la dansabilité et l’énergie, réparties par genre, pour approfondir notre compréhension des caractéristiques musicales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme pour la répartition des genres\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = genre_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution des genres de playlist\", fontsize=16)\n",
    "plt.xlabel(\"Genre\", fontsize=14)\n",
    "plt.ylabel(\"Nombre de pistes\", fontsize=14)\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=1, alpha=0.7)\n",
    "\n",
    "# Le bout de code suivant, gérant l'affichage des valeurs sur les barres a été généré avec ChatGPT :\n",
    "# Affichage des valeurs au-dessus des barres\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    plt.text(\n",
    "        p.get_x() + p.get_width() / 2,  # Position en x (centre de la barre)\n",
    "        height,  # Position en y (hauteur de la barre)\n",
    "        f\"{int(height)}\",  # Texte à afficher\n",
    "        ha=\"center\",  # Alignement horizontal\n",
    "        va=\"bottom\",  # Alignement vertical\n",
    "        fontsize=12,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'une matrice de corrélation entre les variables numériques\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = train_df[num_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Matrice de corrélation des variables numériques\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule la popularité moyenne des pistes pour chaque genre de playlist\n",
    "popularity_by_genre = train_df.groupby(\"playlist_genre\")[\"track_popularity\"].mean()\n",
    "print(popularity_by_genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuage de points montrant la relation entre la dansabilité, l'énergie et le genre de playlist\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=train_df, x=\"danceability\", y=\"energy\", hue=\"playlist_genre\")\n",
    "plt.title(\"Relation entre la dansabilité et l'énergie par genre\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue une exploration préliminaire des données : il charge les fichiers d’entraînement et de test, examine la structure des données (types de variables, dimensions), calcule des statistiques descriptives, puis visualise les distributions, la répartition des genres, et les relations entre variables numériques. Ces analyses offrent une première compréhension de l’ensemble de données et posent les bases pour des traitements et modèles plus avancés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 :** Application d'algorithmes standards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données d'entraînement\n",
    "train_df = pd.read_csv(\"train.csv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes quantitatives\n",
    "quantitative_columns = [\n",
    "    \"track_popularity\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"key\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\",\n",
    "    \"duration_ms\",\n",
    "]\n",
    "\n",
    "# Sélection des features (X)\n",
    "X = train_df[quantitative_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible\n",
    "y = train_df[\"playlist_genre\"]\n",
    "\n",
    "# Encodage des labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement (80%) et de test (20%).\n",
    "# `random_state` fixe la graine pour obtenir une division reproductible.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un scaler pour standardiser les données (moyenne = 0, écart-type = 1).\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustement du scaler sur les données d'entraînement et transformation des données d'entraînement.\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformation des données de test en utilisant les paramètres appris sur l'ensemble d'entraînement.\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un classificateur SVM (Support Vector Machine).\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Entraînement du SVM sur les données d'entraînement standardisées.\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des étiquettes pour les données de test standardisées.\n",
    "y_pred_svm = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calcul de la précision du SVM sur l'ensemble de test.\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Affichage de la précision obtenue.\n",
    "print(f\"Accuracy du SVM : {accuracy_svm:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de décision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un classificateur Arbre de Décision.\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Entraînement de l'Arbre de Décision sur les données d'entraînement (non standardisées).\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des étiquettes pour les données de test.\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calcul de la précision de l'Arbre de Décision sur l'ensemble de test.\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Affichage de la précision obtenue.\n",
    "print(f\"Accuracy de l'Arbre de Décision : {accuracy_dt:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un classificateur K-Nearest Neighbors (KNN).\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Entraînement du KNN sur les données d'entraînement standardisées.\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des étiquettes pour les données de test standardisées.\n",
    "y_pred_knn = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calcul de la précision du KNN sur l'ensemble de test.\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Affichage de la précision obtenue.\n",
    "print(f\"Accuracy du KNN : {accuracy_knn:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un classificateur Random Forest.\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Entraînement du Random Forest sur les données d'entraînement (non standardisées).\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des étiquettes pour les données de test.\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calcul de la précision du Random Forest sur l'ensemble de test.\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Affichage de la précision obtenue.\n",
    "print(f\"Accuracy du Random Forest : {accuracy_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Logistique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un classificateur de Régression Logistique avec un nombre maximum d'itérations fixé à 1000.\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entraînement de la Régression Logistique sur les données d'entraînement standardisées.\n",
    "lr_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction des étiquettes pour les données de test standardisées.\n",
    "y_pred_lr = lr_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calcul de la précision de la Régression Logistique sur l'ensemble de test.\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Affichage de la précision obtenue.\n",
    "print(f\"Accuracy de la Régression Logistique : {accuracy_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des résultats finaux pour tous les modèles entraînés.\n",
    "print(\"\\nRésultats des modèles :\\n\")\n",
    "print(f\"Accuracy du Random Forest : {accuracy_rf:.2f}\")\n",
    "print(f\"Accuracy du SVM : {accuracy_svm:.2f}\")\n",
    "print(f\"Accuracy de la Régression Logistique : {accuracy_lr:.2f}\")\n",
    "print(f\"Accuracy du KNN : {accuracy_knn:.2f}\")\n",
    "print(f\"Accuracy de l'Arbre de Décision : {accuracy_dt:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **INTERESTING TO LOOK AT BECAUSE RANDOM FOREST IS THE BEST ONE**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du rapport de classification pour le modèle Random Forest.\n",
    "print(\"\\nRapport de classification pour le Random Forest :\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
    "# Le rapport inclut des métriques comme la précision, le rappel, et le F1-score pour chaque classe.\n",
    "\n",
    "# Affichage de la matrice de confusion pour le modèle Random Forest.\n",
    "print(\"\\n\\n\\nMatrice de confusion pour le Random Forest :\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "# La matrice de confusion montre le nombre de prédictions correctes et erronées pour chaque classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée pour le Random Forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calcule les scores de précision pour chaque fold\n",
    "scores = cross_val_score(rf_classifier, X, y_encoded, cv=5)\n",
    "# Affiche les scores de chaque fold\n",
    "print(f\"Scores de validation croisée (Random Forest) : {scores}\")\n",
    "# Affiche la moyenne des scores, indicateur global de performance\n",
    "print(f\"Score moyen : {scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La case suivante prend 8 minutes à elle seule pour tourner, les résultats que j'ai obtenu sont les suivants :\n",
    "\n",
    "- Meilleurs paramètres : {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "- Meilleure score : 0.56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recherche des meilleurs hyperparamètres pour le Random Forest à l'aide de GridSearchCV.\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Définition de la grille d'hyperparamètres à tester.\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],  # Nombre d'arbres dans la forêt\n",
    "#     'max_depth': [None, 5, 10, 20],  # Profondeur maximale des arbres\n",
    "#     'min_samples_split': [2, 5, 10]  # Nombre minimum d'échantillons pour diviser un nœud\n",
    "# }\n",
    "\n",
    "# # Initialisation de GridSearchCV avec validation croisée (5 folds).\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "# # Entraînement et recherche des meilleurs hyperparamètres.\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Affichage des meilleurs paramètres trouvés et du meilleur score moyen obtenu.\n",
    "# print(f\"Meilleurs paramètres : {grid_search.best_params_}\")  # Hyperparamètres optimaux\n",
    "# print(f\"Meilleur score : {grid_search.best_score_:.2f}\")  # Meilleure précision moyenne sur les folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul et affichage de l'importance des caractéristiques pour le modèle Random Forest.\n",
    "# Importance des caractéristiques calculée par le modèle\n",
    "importances = rf_classifier.feature_importances_\n",
    "# Tri des indices des caractéristiques par ordre décroissant d'importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Importance des caractéristiques :\")\n",
    "# Parcours des caractéristiques en fonction de leur importance\n",
    "for f in range(X.shape[1]):\n",
    "    # Affiche le rang, le nom de la caractéristique (tiré de quantitative_columns), et son importance\n",
    "    print(\n",
    "        f\"{f + 1}. {quantitative_columns[indices[f]]} ({importances[indices[f]]:.4f})\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
