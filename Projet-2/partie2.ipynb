{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Partie 2 :** Développement d’une architecture de classification sur la base des caractéristiques sonores\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonctions1 import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et préprocessing des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du train\n",
    "train_df = pd.read_csv(\"train.csv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection des colonnes quantitatives pour les caractéristiques (features).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"danceability\",  # Mesure de la capacité à danser (0 à 1)\n",
    "    \"energy\",  # Intensité et activité globale de la piste\n",
    "    \"key\",  # Tonalité musicale (0 à 11)\n",
    "    \"loudness\",  # Niveau sonore moyen en décibels\n",
    "    \"mode\",  # Mode (majeur = 1, mineur = 0)\n",
    "    \"speechiness\",  # Mesure de la présence de paroles\n",
    "    \"acousticness\",  # Probabilité qu'il s'agisse d'une piste acoustique\n",
    "    \"instrumentalness\",  # Mesure de l'absence de paroles\n",
    "    \"liveness\",  # Probabilité qu'il s'agisse d'un enregistrement live\n",
    "    \"valence\",  # Mesure de la positivité musicale (0 à 1)\n",
    "    \"tempo\",  # Tempo de la piste en battements par minute (BPM)\n",
    "    \"duration_ms\",  # Durée de la piste en millisecondes\n",
    "]\n",
    "\n",
    "# Extraction des caractéristiques (X) et des étiquettes (y) à partir du DataFrame d'entraînement.\n",
    "X = train_df[num_cols].values  # Matrice des valeurs des colonnes quantitatives\n",
    "y = train_df[\"playlist_genre\"].values  # Vecteur des étiquettes de genres de playlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage manuel des labels pour convertir les genres en indices numériques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des genres uniques présents dans y\n",
    "unique_genres = np.unique(y)\n",
    "\n",
    "# Création d'un mapping genre -> index\n",
    "genre_to_idx = {g: i for i, g in enumerate(unique_genres)}\n",
    "\n",
    "# Conversion des genres en indices numériques\n",
    "y_encoded = np.array([genre_to_idx[g] for g in y])\n",
    "\n",
    "# Calcul du nombre total de classes (genres uniques).\n",
    "num_classes = len(unique_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données (Standardisation) pour avoir une moyenne nulle et un écart-type unitaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean(axis=0)  # Calcul de la moyenne pour chaque colonne (caractéristique)\n",
    "std = X.std(axis=0)  # Calcul de l'écart-type pour chaque colonne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données : soustraction de la moyenne et division par l'écart-type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une petite constante (1e-9) est ajoutée au dénominateur pour éviter une division par zéro.\n",
    "X = (X - mean) / (std + 1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation train/validation/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation Train/Val depuis le train.csv (85% train, 15% val)\n",
    "n = len(X)  # Nombre total d'exemples\n",
    "idx = np.arange(n)  # Création d'indices pour les exemples\n",
    "np.random.shuffle(idx)  # Mélange aléatoire des indices\n",
    "X = X[idx]  # Réarrangement des caractéristiques selon les indices mélangés\n",
    "y_encoded = y_encoded[idx]  # Réarrangement des étiquettes correspondantes\n",
    "\n",
    "train_ratio = 0.85\n",
    "train_size = int(train_ratio * n)\n",
    "\n",
    "# Découpage des ensembles\n",
    "X_train = X[:train_size]  # Données d'entraînement\n",
    "y_train = y_encoded[:train_size]  # Étiquettes d'entraînement\n",
    "\n",
    "X_val = X[train_size:]  # Données de validation\n",
    "y_val = y_encoded[train_size:]  # Étiquettes de validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du test\n",
    "test_df = pd.read_csv(\"test.csv\", sep=\"\\t\")\n",
    "\n",
    "X_test = test_df[num_cols].values\n",
    "y_test = test_df[\"playlist_genre\"].values\n",
    "y_test = np.array([genre_to_idx[g] for g in y_test])  # Encodage avec le même mapping\n",
    "\n",
    "# On normalise le test avec le mean/std du train\n",
    "X_test = (X_test - mean) / (std + 1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Définition des configurations à tester\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LONG : 1h 4min 30s\n",
    "\n",
    "Utilisez `ctrl+/` pour décommenter les lignes selectionnées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_configs = [\n",
    "#     [],  # Pas de couche cachée\n",
    "#     [2],  # Une couche cachée avec 2 neurone\n",
    "#     [2, 4, 8, 16, 32, 64],  # etc\n",
    "#     # [2, 4, 8, 16, 32, 64, 32, 16, 8, 4, 2],  # etc\n",
    "#     [128],\n",
    "#     [512, 512],\n",
    "#     [64, 64, 64],\n",
    "# ]\n",
    "\n",
    "# batch_sizes = [32, 64, 256]\n",
    "# learning_rates = [0.01, 0.001, 0.0001]\n",
    "# dropout_rates = [0.0, 0.5]\n",
    "# use_batchnorm_options = [False, True]\n",
    "# clip_norm_values = [None, 1.0]\n",
    "\n",
    "# results = []  # pour stocker toutes les configurations testées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAPIDE : 1min 45s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_configs = [\n",
    "    [512, 512],\n",
    "]\n",
    "\n",
    "batch_sizes = [32]\n",
    "learning_rates = [0.01]\n",
    "dropout_rates = [0.0]\n",
    "use_batchnorm_options = [True]\n",
    "clip_norm_values = [1.0]\n",
    "\n",
    "results = []  # pour stocker toutes les configurations testées\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Boucle d'expérimentation sur plusieurs hyperparamètres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle d'exploration pour tester différentes configurations hyperparamétriques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in layer_configs:  # Configurations des couches\n",
    "    for bs in batch_sizes:  # Tailles de mini-lots\n",
    "        for lr in learning_rates:  # Taux d'apprentissage\n",
    "            for do_rate in dropout_rates:  # Taux de dropout\n",
    "                for bn in use_batchnorm_options:  # Batch Normalization\n",
    "                    for cn in clip_norm_values:  # Valeurs de clip norm\n",
    "\n",
    "                        # Affichage de la configuration en cours\n",
    "                        print(\n",
    "                            f\"\\nConfiguration: Layers={layers}, Batch={bs}, LR={lr}, Dropout={do_rate}, BN={bn}, ClipNorm={cn}\"\n",
    "                        )\n",
    "\n",
    "                        # Instanciation du modèle avec les heuristiques\n",
    "                        model = MLP(\n",
    "                            # Dimension des caractéristiques\n",
    "                            input_dim=X_train.shape[1],\n",
    "                            layer_sizes=layers,  # Taille des couches cachées\n",
    "                            num_classes=num_classes,  # Nombre de classes\n",
    "                            dropout_rate=do_rate,  # Taux de dropout\n",
    "                            use_batchnorm=bn,  # Activation de Batch Normalization\n",
    "                            clip_norm=cn,  # Valeur de clip norm\n",
    "                        )\n",
    "\n",
    "                        # Entraînement du modèle avec les hyperparamètres actuels\n",
    "                        history = train_model(\n",
    "                            model,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            X_val,\n",
    "                            y_val,\n",
    "                            epochs=20,  # Nombre d'époques\n",
    "                            batch_size=bs,  # Taille de mini-lots\n",
    "                            lr=lr,  # Taux d'apprentissage\n",
    "                            verbose=False,  # Désactivation de l'affichage détaillé pendant l'entraînement\n",
    "                        )\n",
    "\n",
    "                        # Récupération de la précision finale sur l'ensemble de validation\n",
    "                        val_acc = history[\"val_acc\"][-1]\n",
    "                        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "                        # Stockage des résultats pour cette configuration\n",
    "                        results.append(\n",
    "                            (val_acc, layers, bs, lr, do_rate, bn, cn, history, model)\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extraction des trois meilleures configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tri des résultats en fonction de la précision de validation (val_acc) en ordre décroissant.\n",
    "results.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Sélection des 10 meilleures configurations.\n",
    "top_10 = results[:10]\n",
    "\n",
    "# Affichage des 10 meilleures configurations avec leurs hyperparamètres et précision.\n",
    "print(\"\\nTop 10 des configurations (Val Accuracy):\")\n",
    "for i, (val_acc, layers, bs, lr, do_rate, bn, cn, hist, mdl) in enumerate(\n",
    "    top_10, start=1\n",
    "):\n",
    "    print(\n",
    "        f\"{i}) Accuracy = {val_acc:.4f}, Layers = {layers}, Batch = {bs}, LR={lr}, Dropout = {do_rate}, BN = {bn}, ClipNorm = {cn}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tracés des courbes d’apprentissage pour le meilleur modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de la meilleure configuration parmi le top 10.\n",
    "(\n",
    "    best_val_acc,  # Meilleure précision de validation\n",
    "    best_layers,  # Configuration des couches du réseau\n",
    "    best_bs,  # Taille de batch\n",
    "    best_lr,  # Taux d'apprentissage\n",
    "    best_do,  # Taux de dropout\n",
    "    best_bn,  # Indicateur Batch Normalization (True/False)\n",
    "    best_cn,  # Valeur de Clip Norm\n",
    "    best_history,  # Historique des métriques d'entraînement\n",
    "    best_model,  # Modèle correspondant à la meilleure configuration\n",
    ") = top_10[\n",
    "    0\n",
    "]  # Sélection de la première configuration parmi les top 10 (meilleure Val Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Courbe de la loss (gauche)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(best_history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(best_history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Courbe de la Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Courbe de l'accuracy (droite)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(best_history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(best_history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Courbe de l'Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation finale sur le test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des activations finales sur le test set avec le modèle de la meilleure configuration.\n",
    "test_activations, _, _ = best_model.forward(\n",
    "    X_test, training=False\n",
    ")  # Passe avant sans mode entraînement\n",
    "\n",
    "test_activations = test_activations[\n",
    "    -1\n",
    "]  # Récupération des activations finales (sortie softmax)\n",
    "\n",
    "# Calcul des métriques sur le test set\n",
    "test_loss = cross_entropy_loss(\n",
    "    test_activations, y_test\n",
    ")  # Perte (cross-entropy) sur le test set\n",
    "\n",
    "test_acc = accuracy(test_activations, y_test)  # Précision sur le test set\n",
    "\n",
    "# Affichage des résultats finaux avec les métriques et les hyperparamètres de la meilleure configuration.\n",
    "print(\n",
    "    f\"Performance sur le test set (Meilleure config) :\\n\"\n",
    "    f\"\\tLoss = {test_loss:.4f}\\n\"  # Affichage de la perte\n",
    "    f\"\\tAccuracy = {100 * test_acc:.2f}%\\n\"  # Affichage de la précision en pourcentage\n",
    "    f\"\\nParamètres de la meilleure architecture :\\n\"\n",
    "    f\"\\tCouches = {best_layers}\\n\"  # Nombre et taille des couches cachées\n",
    "    f\"\\tBatch Size = {best_bs}\\n\"  # Taille des mini-lots\n",
    "    f\"\\tLearning Rate = {best_lr}\\n\"  # Taux d'apprentissage\n",
    "    f\"\\tDropout = {best_do}\\n\"  # Taux de dropout\n",
    "    f\"\\tBatchNorm = {best_bn}\\n\"  # Utilisation de Batch Normalization\n",
    "    f\"\\tClipNorm = {best_cn}\"  # Valeur de Clip Norm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Génération d'un fichier CSV avec les prédictions du modèle sur le test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction des classes sur le test set\n",
    "y_pred_idx = best_model.predict(X_test)\n",
    "\n",
    "# Inverse mapping des indices vers les genres\n",
    "idx_to_genre = {v: k for k, v in genre_to_idx.items()}\n",
    "y_pred_genres = [idx_to_genre[idx] for idx in y_pred_idx]\n",
    "\n",
    "# Création d'une copie du test_df\n",
    "prediction_df = test_df.copy()\n",
    "\n",
    "# Remplacement de la colonne \"playlist_genre\" par les prédictions\n",
    "prediction_df[\"playlist_genre\"] = y_pred_genres\n",
    "\n",
    "# Sauvegarde du nouveau CSV avec les prédictions\n",
    "prediction_df.to_csv(\"KHALFALLAH_prediction_base.csv\", sep=\"\\t\", index=False)\n",
    "print(\"Fichier 'KHALFALLAH_prediction_base.csv' créé ou modifié avec les prédictions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
